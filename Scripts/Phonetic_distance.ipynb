{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eng_to_ipa\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'TV', 'a', 'about', 'above', 'after', 'airplane', 'all', 'alligator', 'am', 'an', 'and', 'animal', 'ankle', 'another', 'ant', 'any', 'apple', 'applesauce', 'are', 'arm', 'around', 'asleep', 'at', 'aunt', 'awake', 'away', 'baby', 'babysitter', 'back', 'backyard', 'bad', 'ball', 'balloon', 'banana', 'basement', 'basket', 'bat', 'bath', 'bathroom', 'bathtub', 'be', 'beach', 'beads', 'beans', 'bear', 'because', 'bed', 'bedroom', 'bee', 'before', 'behind', 'belt', 'bench', 'beside', 'better', 'bib', 'bicycle', 'big', 'bird', 'bite', 'black', 'blanket', 'block', 'blow', 'blue', 'boat', 'book', 'boots', 'bottle', 'bowl', 'box', 'boy', 'bread', 'break', 'breakfast', 'bring', 'broken', 'broom', 'brother', 'brown', 'brush', 'bubbles', 'bucket', 'bug', 'build', 'bump', 'bunny', 'bus', 'but', 'butter', 'butterfly', 'buttocks', 'button', 'buy', 'by', 'bye', 'cake', 'call', 'camera', 'camping', 'can', 'candy', 'car', 'careful', 'carrots', 'carry', 'cat', 'catch', 'cereal', 'chair', 'chalk', 'chase', 'cheek', 'cheerios', 'cheese', 'chicken', 'child', 'chin', 'chocolate', 'church', 'circus', 'clap', 'clean', 'climb', 'clock', 'close', 'closet', 'cloud', 'clown', 'coat', 'coffee', 'coke', 'cold', 'comb', 'cook', 'cookie', 'corn', 'couch', 'could', 'country', 'cover', 'cow', 'cowboy', 'cracker', 'crayon', 'crib', 'cry', 'cup', 'cut', 'cute', 'daddy', 'dance', 'dark', 'day', 'deer', 'diaper', 'dinner', 'dirty', 'dish', 'do', 'doctor', 'does', 'dog', 'doll', \"don't\", 'donkey', 'donut', 'door', 'down', 'downtown', 'draw', 'drawer', 'dress', 'drink', 'drive', 'drop', 'dry', 'dryer', 'duck', 'dump', 'each', 'ear', 'eat', 'egg', 'elephant', 'empty', 'every', 'eye', 'face', 'fall', 'farm', 'fast', 'feed', 'find', 'fine', 'finger', 'finish', 'fireman', 'firetruck', 'first', 'fish', 'fit', 'fix', 'flag', 'flower', 'food', 'foot', 'for', 'fork', 'friend', 'frog', 'full', 'game', 'garage', 'garbage', 'garden', 'gentle', 'get', 'giraffe', 'girl', 'give', 'glass', 'glasses', 'gloves', 'glue', 'go', 'good', 'goose', 'grandma', 'grandpa', 'grapes', 'grass', 'green', 'gum', 'hair', 'hamburger', 'hammer', 'hand', 'happy', 'hard', 'hat', 'hate', 'have', 'he', 'head', 'hear', 'heavy', 'helicopter', 'hello', 'help', 'hen', 'her', 'here', 'hers', 'hi', 'hide', 'high', 'him', 'his', 'hit', 'hold', 'home', 'horse', 'hose', 'hot', 'house', 'how', 'hug', 'hungry', 'hurry', 'hurt', 'ice', 'if', 'inside', 'into', 'is', 'it', 'jacket', 'jar', 'jeans', 'jello', 'jelly', 'juice', 'jump', 'keys', 'kick', 'kiss', 'kitchen', 'kitty', 'knee', 'knife', 'knock', 'ladder', 'lady', 'lamb', 'lamp', 'last', 'later', 'leg', 'lick', 'light', 'like', 'lion', 'lips', 'listen', 'little', 'lollipop', 'long', 'look', 'loud', 'love', 'lunch', 'mad', 'mailman', 'make', 'man', 'me', 'meat', 'medicine', 'melon', 'milk', 'mine', 'mittens', 'mommy', 'money', 'monkey', 'moon', 'moose', 'mop', 'more', 'morning', 'motorcycle', 'mouse', 'mouth', 'movie', 'much', 'muffin', 'my', 'myself', 'nail', 'nap', 'napkin', 'naughty', 'necklace', 'new', 'nice', 'night', 'no', 'noisy', 'none', 'noodles', 'nose', 'not', 'now', 'nurse', 'nuts', 'of', 'off', 'old', 'on', 'open', 'orange', 'other', 'our', 'out', 'outside', 'oven', 'over', 'owl', 'paint', 'pajamas', 'pancake', 'pants', 'paper', 'park', 'party', 'pattycake', 'peas', 'peekaboo', 'pen', 'pencil', 'penguin', 'penis', 'penny', 'people', 'person', 'pick', 'pickle', 'picnic', 'picture', 'pig', 'pillow', 'pizza', 'plant', 'plate', 'play', 'playground', 'please', 'police', 'pony', 'pool', 'poor', 'popcorn', 'popsicle', 'porch', 'potato', 'potty', 'pour', 'present', 'pretend', 'pretty', 'pretzel', 'pudding', 'pull', 'pumpkin', 'puppy', 'purse', 'push', 'put', 'puzzle', 'quiet', 'radio', 'rain', 'raisin', 'read', 'red', 'refrigerator', 'ride', 'rip', 'rock', 'roof', 'room', 'rooster', 'run', 'sad', 'salt', 'same', 'sandbox', 'sandwich', 'sauce', 'say', 'scared', 'scarf', 'school', 'scissors', 'see', 'shake', 'share', 'she', 'sheep', 'shh', 'shirt', 'shoe', 'shopping', 'shorts', 'shoulder', 'shovel', 'show', 'shower', 'sick', 'sidewalk', 'sing', 'sink', 'sister', 'sit', 'skate', 'sky', 'sled', 'sleep', 'sleepy', 'slide', 'slipper', 'slow', 'smile', 'snack', 'sneaker', 'snow', 'snowman', 'snowsuit', 'so', 'soap', 'sock', 'soda', 'sofa', 'soft', 'some', 'soup', 'spaghetti', 'spill', 'splash', 'spoon', 'sprinkler', 'squirrel', 'stairs', 'stand', 'star', 'stay', 'stick', 'sticky', 'stone', 'stop', 'store', 'story', 'stove', 'strawberry', 'street', 'stroller', 'stuck', 'sun', 'sweater', 'sweep', 'swim', 'swing', 'table', 'take', 'talk', 'tape', 'taste', 'teacher', 'tear', 'teddybear', 'telephone', 'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'think', 'thirsty', 'this', 'those', 'throw', 'tickle', 'tiger', 'tights', 'time', 'tiny', 'tired', 'tissue', 'to', 'toast', 'today', 'toe', 'tomorrow', 'tongue', 'tonight', 'too', 'tooth', 'toothbrush', 'touch', 'towel', 'toy', 'tractor', 'train', 'trash', 'tray', 'tree', 'tricycle', 'truck', 'tummy', 'tuna', 'turkey', 'turtle', 'uncle', 'under', 'underpants', 'up', 'us', 'vacuum', 'vagina', 'vanilla', 'vitamins', 'wait', 'wake', 'walk', 'walker', 'was', 'wash', 'watch', 'water', 'we', 'were', 'wet', 'what', 'when', 'where', 'which', 'white', 'who', 'why', 'will', 'wind', 'window', 'windy', 'wipe', 'wish', 'with', 'wolf', 'woods', 'work', 'would', 'write', 'yard', 'yellow', 'yes', 'yesterday', 'yogurt', 'you', 'your', 'yourself', 'yucky', 'zebra', 'zipper', 'zoo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data\n",
    "data = pd.read_csv('/Users/tildeidunsloth/Desktop/bachelor/Bachelor/Data/75kidsubset.csv')\n",
    "\n",
    "# Making list with words from dataset\n",
    "data['item_definition']\n",
    "item_list = data['item_definition'].tolist()\n",
    "len(item_list)\n",
    "\n",
    "# New list with unique items\n",
    "unique_items = set(item_list)\n",
    "type(unique_items)\n",
    "\n",
    "# Making sure it is a list (because of problems with set)\n",
    "unique_items_list = sorted(unique_items)\n",
    "print(unique_items_list)\n",
    "type(unique_items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aɪ', 'ˌtɛləˈvɪʒən', 'ə', 'əˈbaʊt', 'əˈbəv', 'ˈæftər', 'ˈɛrˌpleɪn', 'ɔl', 'ˈæləˌgeɪtər', 'æm', 'ən', 'ənd', 'ˈænəməl', 'ˈæŋkəl', 'əˈnəðər', 'ænt', 'ˈɛni', 'ˈæpəl', 'ˈæpəlˌsɔs', 'ər', 'ɑrm', 'əraʊnd', 'əsˈlip', 'æt', 'ɔnt', 'əˈweɪk', 'əˈweɪ', 'ˈbeɪbi', 'ˈbeɪbiˌsɪtər', 'bæk', 'ˈbæˌkjɑrd', 'bæd', 'bɔl', 'bəˈlun', 'bəˈnænə', 'ˈbeɪsmənt', 'ˈbæskət', 'bæt', 'bæθ', 'ˈbæθˌrum', 'ˈbæθtəb', 'bi', 'biʧ', 'bidz', 'binz', 'bɛr', 'bɪˈkəz', 'bɛd', 'ˈbɛˌdrum', 'bi', 'ˌbiˈfɔr', 'bɪˈhaɪnd', 'bɛlt', 'bɛnʧ', 'ˌbiˈsaɪd', 'ˈbɛtər', 'bɪb', 'ˈbaɪsɪkəl', 'bɪg', 'bərd', 'baɪt', 'blæk', 'ˈblæŋkɪt', 'blɑk', 'bloʊ', 'blu', 'boʊt', 'bʊk', 'buts', 'ˈbɑtəl', 'boʊl', 'bɑks', 'bɔɪ', 'brɛd', 'breɪk', 'ˈbrɛkfəst', 'brɪŋ', 'ˈbroʊkən', 'brum', 'ˈbrəðər', 'braʊn', 'brəʃ', 'ˈbəbəlz', 'ˈbəkɪt', 'bəg', 'bɪld', 'bəmp', 'ˈbəni', 'bəs', 'bət', 'ˈbətər', 'ˈbətərˌflaɪ', 'ˈbətəks', 'ˈbətən', 'baɪ', 'baɪ', 'baɪ', 'keɪk', 'kɔl', 'ˈkæmərə', 'ˈkæmpɪŋ', 'kən', 'ˈkændi', 'kɑr', 'ˈkɛrfəl', 'ˈkɛrəts', 'ˈkɛri', 'kæt', 'kæʧ', 'ˈsɪriəl', 'ʧɛr', 'ʧɔk', 'ʧeɪs', 'ʧik', 'ˈʧɪrioʊs', 'ʧiz', 'ˈʧɪkən', 'ʧaɪld', 'ʧɪn', 'ˈʧɔklət', 'ʧərʧ', 'ˈsərkəs', 'klæp', 'klin', 'klaɪm', 'klɑk', 'kloʊz', 'ˈklɑzət', 'klaʊd', 'klaʊn', 'koʊt', 'ˈkɔfi', 'koʊk', 'koʊld', 'koʊm', 'kʊk', 'ˈkʊki', 'kɔrn', 'kaʊʧ', 'kʊd', 'ˈkəntri', 'ˈkəvər', 'kaʊ', 'ˈkaʊˌbɔɪ', 'ˈkrækər', 'kreɪɑn', 'krɪb', 'kraɪ', 'kəp', 'kət', 'kjut', 'ˈdædi', 'dæns', 'dɑrk', 'deɪ', 'dɪr', 'ˈdaɪpər', 'ˈdɪnər', 'ˈdərti', 'dɪʃ', 'du', 'ˈdɔktər', 'dɪz', 'dɔg', 'dɑl', 'doʊnt', 'ˈdɔŋki', 'ˈdoʊˌnət', 'dɔr', 'daʊn', 'ˈdaʊnˈtaʊn', 'drɔ', 'drɔr', 'drɛs', 'drɪŋk', 'draɪv', 'drɔp', 'draɪ', 'draɪər', 'dək', 'dəmp', 'iʧ', 'ɪr', 'it', 'ɛg', 'ˈɛləfənt', 'ˈɛmti', 'ˈɛvəri', 'aɪ', 'feɪs', 'fɔl', 'fɑrm', 'fæst', 'fid', 'faɪnd', 'faɪn', 'ˈfɪŋgər', 'ˈfɪnɪʃ', 'ˈfaɪrmən', 'firetruck*', 'fərst', 'fɪʃ', 'fɪt', 'fɪks', 'flæg', 'flaʊər', 'fud', 'fʊt', 'fər', 'fɔrk', 'frɛnd', 'frɑg', 'fʊl', 'geɪm', 'gərɑʒ', 'ˈgɑrbɪʤ', 'ˈgɑrdən', 'ˈʤɛnəl', 'gɪt', 'ʤəræf', 'gərl', 'gɪv', 'glæs', 'ˈglæsɪz', 'gləvz', 'glu', 'goʊ', 'gʊd', 'gus', 'ˈgrændmɑ', 'ˈgrændˌpɑ', 'greɪps', 'græs', 'grin', 'gəm', 'hɛr', 'ˈhæmbərgər', 'ˈhæmər', 'hænd', 'ˈhæpi', 'hɑrd', 'hæt', 'heɪt', 'hæv', 'hi', 'hɛd', 'hir', 'ˈhɛvi', 'ˈhɛlɪˌkɑptər', 'hɛˈloʊ', 'hɛlp', 'hɛn', 'hər', 'hir', 'hərz', 'haɪ', 'haɪd', 'haɪ', 'ɪm', 'hɪz', 'hɪt', 'hoʊld', 'hoʊm', 'hɔrs', 'hoʊz', 'hɑt', 'haʊs', 'haʊ', 'həg', 'ˈhəŋgri', 'ˈhəri', 'hərt', 'aɪs', 'ɪf', 'ˌɪnˈsaɪd', 'ˈɪntu', 'ɪz', 'ɪt', 'ˈʤækɪt', 'ʤɑr', 'ʤinz', 'ˈʤɛloʊ', 'ˈʤɛli', 'ʤus', 'ʤəmp', 'kiz', 'kɪk', 'kɪs', 'ˈkɪʧən', 'ˈkɪti', 'ni', 'naɪf', 'nɑk', 'ˈlædər', 'ˈleɪdi', 'læm', 'læmp', 'læst', 'ˈleɪtər', 'lɛg', 'lɪk', 'laɪt', 'laɪk', 'laɪən', 'lɪps', 'ˈlɪsən', 'ˈlɪtəl', 'ˈlɑliˌpɑp', 'lɔŋ', 'lʊk', 'laʊd', 'ləv', 'lənʧ', 'mæd', 'ˈmeɪlˌmæn', 'meɪk', 'mæn', 'mi', 'mit', 'ˈmɛdəsən', 'ˈmɛlən', 'mɪlk', 'maɪn', 'ˈmɪtənz', 'ˈmɑmi', 'ˈməni', 'ˈməŋki', 'mun', 'mus', 'mɑp', 'mɔr', 'ˈmɔrnɪŋ', 'ˈmoʊtərˌsaɪkəl', 'maʊs', 'maʊθ', 'ˈmuvi', 'məʧ', 'ˈməfən', 'maɪ', 'ˌmaɪˈsɛlf', 'neɪl', 'næp', 'ˈnæpkɪn', 'ˈnɔti', 'ˈnɛkləs', 'nu', 'nis', 'naɪt', 'noʊ', 'ˈnɔɪzi', 'nən', 'ˈnudəlz', 'noʊz', 'nɑt', 'naʊ', 'nərs', 'nəts', 'əv', 'ɔf', 'oʊld', 'ɔn', 'ˈoʊpən', 'ˈɔrɪnʤ', 'ˈəðər', 'ɑr', 'aʊt', 'ˈaʊtˈsaɪd', 'ˈəvən', 'ˈoʊvər', 'aʊl', 'peɪnt', 'pəˈʤɑməz', 'ˈpænˌkeɪk', 'pænts', 'ˈpeɪpər', 'pɑrk', 'ˈpɑrti', 'pattycake*', 'piz', 'peekaboo*', 'pɛn', 'ˈpɛnsəl', 'ˈpɛŋgwən', 'ˈpinɪs', 'ˈpɛni', 'ˈpipəl', 'ˈpərsən', 'pɪk', 'ˈpɪkəl', 'ˈpɪkˌnɪk', 'ˈpɪkʧər', 'pɪg', 'ˈpɪloʊ', 'ˈpitsə', 'plænt', 'pleɪt', 'pleɪ', 'ˈpleɪˌgraʊnd', 'pliz', 'pəˈlis', 'ˈpoʊˌni', 'pul', 'pur', 'ˈpɑpˌkɔrn', 'ˈpɑpsɪkəl', 'pɔrʧ', 'pəˈteɪˌtoʊ', 'ˈpɑti', 'pɔr', 'ˈprɛzənt', 'priˈtɛnd', 'ˈprɪti', 'ˈprɛtzəl', 'ˈpʊdɪŋ', 'pʊl', 'ˈpəmpkɪn', 'ˈpəpi', 'pərs', 'pʊʃ', 'pʊt', 'ˈpəzəl', 'kwaɪət', 'ˈreɪdiˌoʊ', 'reɪn', 'ˈreɪzɪn', 'rɛd', 'rɛd', 'rɪˈfrɪʤərˌeɪtər', 'raɪd', 'rɪp', 'rɑk', 'rʊf', 'rum', 'ˈrustər', 'rən', 'sæd', 'sɔlt', 'seɪm', 'ˈsændˌbɑks', 'ˈsænwɪʧ', 'sɔs', 'seɪ', 'skɛrd', 'skɑrf', 'skul', 'ˈsɪzərz', 'si', 'ʃeɪk', 'ʃɛr', 'ʃi', 'ʃip', 'shh*', 'ʃərt', 'ʃu', 'ˈʃɑpɪŋ', 'ʃɔrts', 'ˈʃoʊldər', 'ˈʃəvəl', 'ʃoʊ', 'ʃaʊər', 'sɪk', 'ˈsaɪdˌwɔk', 'sɪŋ', 'sɪŋk', 'ˈsɪstər', 'sɪt', 'skeɪt', 'skaɪ', 'slɛd', 'slip', 'sˈlipi', 'slaɪd', 'sˈlɪpər', 'sloʊ', 'smaɪl', 'snæk', 'sˈnikər', 'snoʊ', 'sˈnoʊˌmæn', 'snowsuit*', 'soʊ', 'soʊp', 'sɑk', 'ˈsoʊdə', 'ˈsoʊfə', 'sɔft', 'səm', 'sup', 'spəˈgɛti', 'spɪl', 'splæʃ', 'spun', 'ˈsprɪŋkələr', 'skwərəl', 'stɛrz', 'stænd', 'stɑr', 'steɪ', 'stɪk', 'ˈstɪki', 'stoʊn', 'stɑp', 'stɔr', 'ˈstɔri', 'stoʊv', 'ˈstrɔˌbɛri', 'strit', 'ˈstroʊlər', 'stək', 'sən', 'sˈwɛtər', 'swip', 'swɪm', 'swɪŋ', 'ˈteɪbəl', 'teɪk', 'tɔk', 'teɪp', 'teɪst', 'ˈtiʧər', 'tɪr', 'teddybear*', 'ˈtɛləˌfoʊn', 'ðət', 'ðə', 'ðɛr', 'ðɛm', 'ðɛn', 'ðɛr', 'ðiz', 'ðeɪ', 'θɪŋk', 'ˈθərsti', 'ðɪs', 'ðoʊz', 'θroʊ', 'ˈtɪkəl', 'ˈtaɪgər', 'taɪts', 'taɪm', 'ˈtaɪni', 'taɪərd', 'ˈtɪʃu', 'tɪ', 'toʊst', 'təˈdeɪ', 'toʊ', 'təˈmɑˌroʊ', 'təŋ', 'təˈnaɪt', 'tu', 'tuθ', 'ˈtuθbrəʃ', 'təʧ', 'taʊəl', 'tɔɪ', 'ˈtræktər', 'treɪn', 'træʃ', 'treɪ', 'tri', 'ˈtrɪsɪkəl', 'trək', 'ˈtəmi', 'ˈtunə', 'ˈtərki', 'ˈtərtəl', 'ˈəŋkəl', 'ˈəndər', 'ˈəndərˌpænts', 'əp', 'ˈjuˈɛs', 'ˈvækjum', 'vəˈʤaɪnə', 'vəˈnɪlə', 'ˈvaɪtəmənz', 'weɪt', 'weɪk', 'wɔk', 'ˈwɔkər', 'wɑz', 'wɑʃ', 'wɔʧ', 'ˈwɔtər', 'wi', 'wər', 'wɛt', 'wət', 'wɪn', 'wɛr', 'wɪʧ', 'waɪt', 'hu', 'waɪ', 'wɪl', 'wɪnd', 'ˈwɪndoʊ', 'ˈwɪndi', 'waɪp', 'wɪʃ', 'wɪθ', 'wʊlf', 'wʊdz', 'wərk', 'wʊd', 'raɪt', 'jɑrd', 'ˈjɛloʊ', 'jɛs', 'ˈjɛstərˌdeɪ', 'ˈjoʊgərt', 'ju', 'jʊr', 'ˈjɔrsɛlf', 'ˈjəki', 'ˈzibrə', 'ˈzɪpər', 'zu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming words to phonetics\n",
    "phonetic_items = [] #creating empty list\n",
    "\n",
    "for word in unique_items_list: #looping through list of words \n",
    "    phonetic_representation = eng_to_ipa.convert(word) #converting words to phonetics\n",
    "    phonetic_items.append(phonetic_representation) #appending words to list\n",
    "\n",
    "print(phonetic_items)\n",
    "type(phonetic_items) #check that it's a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Items  \\\n",
      "0  [I, TV, a, about, above, after, airplane, all,...   \n",
      "\n",
      "                                           Phonetics  \n",
      "0  [aɪ, ˌtɛləˈvɪʒən, ə, əˈbaʊt, əˈbəv, ˈæftər, ˈɛ...  \n"
     ]
    }
   ],
   "source": [
    "# Making a dataframe with words and their phonetic transcriptions\n",
    "phonetic_and_words = pd.DataFrame({'Items' : [unique_items_list],\n",
    "                                'Phonetics' : [phonetic_items]},\n",
    "                                columns=['Items','Phonetics'])\n",
    "\n",
    "print(phonetic_and_words) #checking that the words match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function to calculate levenshtein distance/edit distance\n",
    "def levenshtein_distance(word1, word2):\n",
    "    # Make sure word1 is shorter or equal in length to word2\n",
    "    if len(word1) > len(word2):\n",
    "        word1, word2 = word2, word1 #if word1 is bigger than word2, change the order to optimize and reduce iterations\n",
    "\n",
    "    previous_row = range(len(word2) + 1)\n",
    "\n",
    "    for i, c1 in enumerate(word1): #for index(indicates placement in word), character in first word \n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(word2):\n",
    "            insertions = previous_row[j + 1] + 1 #The distance if you were to insert a character into word1\n",
    "            deletions = current_row[j] + 1 #The distance if you were to delete a character from word1\n",
    "            substitutions = previous_row[j] + (c1 != c2) #The distance if you were to substitute one character in word1 with the corresponding character in word2\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "#Testing the function\n",
    "levenshtein_distance(\"elf\", \"elephant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 10.  2. ...  6.  5.  2.]\n",
      " [10.  0. 10. ... 10.  8. 11.]\n",
      " [ 2. 10.  0. ...  5.  5.  2.]\n",
      " ...\n",
      " [ 6. 10.  5. ...  0.  4.  5.]\n",
      " [ 5.  8.  5. ...  4.  0.  5.]\n",
      " [ 2. 11.  2. ...  5.  5.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create Matrix\n",
    "phonetic_matrix = np.zeros((len(phonetic_items), len(phonetic_items)))\n",
    "\n",
    "# Calculate Levenshtein distance for each pair of words\n",
    "for i in range(len(phonetic_items)):\n",
    "    for j in range(len(phonetic_items)):\n",
    "        phonetic_matrix[i, j] = levenshtein_distance(phonetic_items[i], phonetic_items[j])\n",
    "\n",
    "print(phonetic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             I    TV     a  about  above  after  airplane   all  alligator  \\\n",
      "I          0.0  10.0   2.0    5.0    5.0    6.0       8.0   2.0       10.0   \n",
      "TV        10.0   0.0  10.0    9.0    8.0    9.0       9.0  10.0        8.0   \n",
      "a          2.0  10.0   0.0    5.0    4.0    5.0       9.0   2.0       10.0   \n",
      "about      5.0   9.0   5.0    0.0    3.0    6.0       9.0   6.0        9.0   \n",
      "above      5.0   8.0   4.0    3.0    0.0    5.0       9.0   5.0        9.0   \n",
      "...        ...   ...   ...    ...    ...    ...       ...   ...        ...   \n",
      "yourself   8.0  11.0   8.0    8.0    8.0    7.0       7.0   6.0       10.0   \n",
      "yucky      5.0  10.0   4.0    5.0    4.0    5.0       8.0   5.0        9.0   \n",
      "zebra      6.0  10.0   5.0    6.0    5.0    5.0       8.0   6.0        9.0   \n",
      "zipper     5.0   8.0   5.0    6.0    5.0    3.0       7.0   6.0        7.0   \n",
      "zoo        2.0  11.0   2.0    6.0    5.0    6.0       9.0   2.0       11.0   \n",
      "\n",
      "            am  ...   yes  yesterday  yogurt   you  your  yourself  yucky  \\\n",
      "I          2.0  ...   3.0       10.0     8.0   2.0   3.0       8.0    5.0   \n",
      "TV        11.0  ...  10.0       10.0    11.0  11.0  11.0      11.0   10.0   \n",
      "a          2.0  ...   3.0       10.0     7.0   2.0   3.0       8.0    4.0   \n",
      "about      6.0  ...   6.0       10.0     6.0   6.0   5.0       8.0    5.0   \n",
      "above      5.0  ...   5.0       10.0     7.0   5.0   5.0       8.0    4.0   \n",
      "...        ...  ...   ...        ...     ...   ...   ...       ...    ...   \n",
      "yourself   8.0  ...   6.0        8.0     6.0   7.0   6.0       0.0    6.0   \n",
      "yucky      5.0  ...   4.0        8.0     5.0   4.0   4.0       6.0    0.0   \n",
      "zebra      6.0  ...   6.0        9.0     6.0   6.0   5.0       7.0    5.0   \n",
      "zipper     6.0  ...   6.0        8.0     5.0   6.0   5.0       7.0    5.0   \n",
      "zoo        2.0  ...   3.0       11.0     8.0   1.0   3.0       8.0    5.0   \n",
      "\n",
      "          zebra  zipper   zoo  \n",
      "I           6.0     5.0   2.0  \n",
      "TV         10.0     8.0  11.0  \n",
      "a           5.0     5.0   2.0  \n",
      "about       6.0     6.0   6.0  \n",
      "above       5.0     5.0   5.0  \n",
      "...         ...     ...   ...  \n",
      "yourself    7.0     7.0   8.0  \n",
      "yucky       5.0     5.0   5.0  \n",
      "zebra       0.0     4.0   5.0  \n",
      "zipper      4.0     0.0   5.0  \n",
      "zoo         5.0     5.0   0.0  \n",
      "\n",
      "[618 rows x 618 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the semantic distance matrix to look for errors/make sure that the output is correct\n",
    "phonetic_df = pd.DataFrame(phonetic_matrix, columns=unique_items_list, index=unique_items_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(phonetic_df)\n",
    "\n",
    "# Save as csv\n",
    "phonetic_df.to_csv('/Users/tildeidunsloth/Desktop/bachelor/Bachelor/Data/phonetic_distance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
