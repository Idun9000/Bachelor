---
title: "Global_model"
author: "Tilde Sloth"
date: "2023-11-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading Packages
```{r}
pacman::p_load(tidyverse, brms)
```

# Loading Data
```{r}
global_centrality <- read_csv("../Data/Global_centrality.csv")
metadata <-  read_csv("../Data/Cleaned_USA.csv")

# there was weird things about the global_centrality 
# Replace "for." with "for"
global_centrality$item_definition <- gsub("for\\.", "for", global_centrality$item_definition)

# Replace "don.t" with "don't"
global_centrality$item_definition <- gsub("don\\.t", "don't", global_centrality$item_definition)

# Replace "if." with "if"
global_centrality$item_definition <- gsub("if\\.", "if", global_centrality$item_definition)
```
# Crating df for fitting model
```{r}
Global_centrality_df <- merge(global_centrality, metadata, by = "item_definition")

# Adding timepoint column
Timepoint_data <- Global_centrality_df %>% 
    group_by(child_id) %>% 
    distinct(age)%>%
    arrange(child_id, age)%>%
    mutate(Timepoint = rank(age))

Global_centrality_df <- merge(x = Global_centrality_df, y = Timepoint_data, by = c("child_id", "age"))

# Changing value column to Knows_Word column
Global_centrality_df <- Global_centrality_df %>% 
    rename(Knows_Word = value)
    
```


# Simplyfying the data by assuming that all words learned at t1 will also be learned at t2 (even though there are exceptions)
```{r}
#Only interested in t1 and t2 for now
Global_centrality_df <- Global_centrality_df %>% 
    filter(Timepoint == 1 | Timepoint == 2)

# First, create a data frame of known words at timepoint 1
known_at_timepoint_1 <- Global_centrality_df %>%
  filter(Timepoint == 1 & Knows_Word == 1) %>%
  select(child_id, item_definition) # Keep only the necessary columns

# Making sure there are no duplicates
known_at_timepoint_1 <- known_at_timepoint_1 %>%
  distinct(child_id, item_definition, .keep_all = TRUE)

# Create a data frame of known words at timepoint 2
known_at_timepoint_2 <- Global_centrality_df %>%
  filter(Timepoint == 2 & Knows_Word == 1) %>%
  select(child_id, item_definition) # Keep only the necessary columns

# Making sure there are no duplicates
known_at_timepoint_2 <- known_at_timepoint_2 %>%
  distinct(child_id, item_definition, .keep_all = TRUE)

# Figuring out which words are known at t1 but not at t2 so we can check if it works later on
words_known_at_1_not_at_2 <- anti_join(known_at_timepoint_1, known_at_timepoint_2, 
                                       by = c("child_id", "item_definition"))

# Overwriting t2 to knows_word = 1 when word is known at t1 
Global_centrality_df <- Global_centrality_df %>% 
  left_join(known_at_timepoint_1 %>% 
              select(child_id, item_definition) %>% 
              mutate(Knows_Word_at_2 = 1), by = c("child_id", "item_definition")) %>%
  mutate(Knows_Word = ifelse(Timepoint == 2 & !is.na(Knows_Word_at_2), 1, Knows_Word)) %>%
  select(-Knows_Word_at_2) # Removing the helper column

```

# Cleaning up a bit in the columns
```{r}
Global_centrality_df <- Global_centrality_df %>% 
    select(child_id, 
           age, 
           item_definition, 
           Knows_Word,birth_order, 
           caregiver_education, 
           sex,
           Semantic,
           Phonetic,
           Word_length, 
           Timepoint)
```

# Saving
```{r}
write_csv(x = Global_centrality_df,file = "../Data/Cleaned/Global_centrality_DF.csv")
```

# Setting formula
```{r}
formula <- brms::bf(Knows_Word ~ 1 + Semantic + Phonetic + Word_length + (1|child_id))

formula2 <-  brms::bf(Knows_Word ~ 1 + Semantic + Phonetic + Word_length + age + (1|child_id))

```

# Setting priors
```{r}
model_priors <- c(
    prior(normal(0, 3), class = b),
    prior(normal(0, 3), class = Intercept),
    prior(normal(0,2), class = sd)
)

```

# Laoding train and test data + Adding ordered factors
```{r}
# Data is split in seperat script so it doesn't fuck up
Global_centrality_t2_test <- read_csv("../Data/Global_centrality_t2_test.csv")
Global_centrality_t2_training <-  read_csv("../Data/Global_centrality_t2_training.csv")

education_levels<- c("Some Secondary", "Secondary", "Some College", "College", "Some Graduate", "Graduate")
Global_centrality_t2_test <- Global_centrality_t2_test %>% 
    mutate(age = factor(age,
                        ordered = TRUE, 
                        levels = sort(unique(age))),
           caregiver_education = factor(caregiver_education,
                                        ordered = TRUE,
                                        levels = education_levels))

Global_centrality_t2_training <- Global_centrality_t2_training %>% 
    mutate(age = factor(age,
                        ordered = TRUE, 
                        levels = sort(unique(age))),
           caregiver_education = factor(caregiver_education,
                                        ordered = TRUE,
                                        levels = education_levels))
```

# Setting model variables
```{r}
cores <- parallel::detectCores()
chains <- 2
seed <- 123
```


# Model with global centrality
```{r}
Global_centrality_model <- brm(formula,
             data = Global_centrality_t2_training,
             family = bernoulli,
             backend = "cmdstanr",
             prior = model_priors,
             sample_prior = T,
             iter = 1000,
             warmup = 500,
             cores = cores,
             chains = chains,
             seed = seed,
             threads = threading(2),
             stan_model_args = list(stanc_options = list("O1")),
             file = "../Models/Global_centrality_model2.rds"
             )
```

# Model with global centrality k fold
```{r}
Global_centrality_model <- brm(formula,
             data = Global_centrality_df_t2,
             family = bernoulli,
             backend = "cmdstanr",
             prior = model_priors,
             sample_prior = T,
             iter = 1000,
             warmup = 500,
             cores = cores,
             chains = chains,
             seed = seed,
             threads = threading(2),
             stan_model_args = list(stanc_options = list("O1")),
             file = "../Models/Global_centrality_model_kfold1.rds"
             )
```


# Model with age (training data)
```{r}
Global_centrality_model_with_age <- brm(formula2,
             data = Global_centrality_t2_training,
             family = bernoulli,
             backend = "cmdstanr",
             prior = model_priors,
             sample_prior = T,
             iter = 1000,
             warmup = 500,
             cores = cores,
             chains = chains,
             seed = seed,
             threads = threading(2),
             stan_model_args = list(stanc_options = list("O1")),
             file = "../Models/Global_centrality_with_age_training2.rds"
             )

```

# Model with age (kfold)
```{r}
Global_centrality_model_with_age_k <- brm(formula2,
             data = Global_centrality_df_t2,
             family = bernoulli,
             backend = "cmdstanr",
             prior = model_priors,
             sample_prior = T,
             iter = 1000,
             warmup = 500,
             cores = cores,
             chains = chains,
             seed = seed,
             threads = threading(2),
             stan_model_args = list(stanc_options = list("O1")),
             file = "../Models/Global_centrality_with_age_kfold1.rds"
            )

```


# K-fold: global centrality with age
```{r}
# kfold_Global_centrality_with_age <- brms::kfold(Global_centrality_model_with_age_k, K = 5)
# saveRDS(kfold_Global_centrality_with_age, "../Models/kfold_Global_centrality_with_age.rds")

kfold_Global_centrality_with_age <-  readRDS("../Models/kfold_Global_centrality_with_age.rds")
print(kfold_Global_centrality_with_age)
```

# Accuracy: global centrality
```{r}
# Generate posterior predictions
posterior_predictions <- brms::posterior_predict(Global_centrality_model,
                newdata = Global_centrality_t2_test,
                re_formula = NULL, allow_new_levels = TRUE,
                sample_new_levels = "uncertainty")
    
# Calculate mean predicted probabilities for each observation
predicted_probs <- apply(posterior_predictions, 2, mean)

# Convert to binary predictions based on a threshold (e.g., 0.5)
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)

# Assuming your test data has the actual outcomes in a column named 'Knows_Word'
actual_classes <- Global_centrality_t2_test$Knows_Word

# Calculate accuracy
accuracy <- mean(predicted_classes == actual_classes)

# Print accuracy
print(paste("Accuracy:", accuracy))
```


# Accuracy: global centrality with age
```{r}
# Generate posterior predictions
posterior_predictions1 <- brms::posterior_predict(Global_centrality_model_with_age,
                newdata = Global_centrality_t2_test,
                re_formula = NULL, allow_new_levels = TRUE,
                sample_new_levels = "uncertainty")
    
# Calculate mean predicted probabilities for each observation
predicted_probs1 <- apply(posterior_predictions1, 2, mean)

# Convert to binary predictions based on a threshold (e.g., 0.5)
predicted_classes1 <- ifelse(predicted_probs1 > 0.5, 1, 0)

# Assuming your test data has the actual outcomes in a column named 'Knows_Word'
actual_classes1 <- Global_centrality_t2_test$Knows_Word

# Calculate accuracy
accuracy1 <- mean(predicted_classes1 == actual_classes1)

# Print accuracy
print(paste("Accuracy:", accuracy1))
```




