---
title: "Creating_Networks_From_Functions"
author: "Laurits og Tilde (klag til laurits hvis noget er galt)"
date: "2023-10-10"
output: html_documentn
---
# SETUP
## Load packages
```{r}
### install.packages("pacman")
pacman::p_load(tidyverse, igraph, purrr)
```

## Load files into into the environment
All files need to be either the child data or a cleaned adjacency matrix:
```{r}

# Load the child data
Child_Dataframe <- read_csv(file = "../../Bachelor/Data/Cleaned_USA.csv") %>% #Subset of data for quick functions
    arrange(item_definition) %>% # sorter dataen
    arrange(child_id) %>%
    arrange(age) %>%
    distinct(child_id, age,item_definition, .keep_all = TRUE) #Make sure all children are 618 length matrix, by removing duplicates

# Load semantics df
SEMANTIC_EDGES_MATRIX <- as.matrix(read.delim(file = "../Data/Cleaned/SEMANTIC_EDGES_MATRIX.txt", sep = ","))

# Load phonetic distance df
PHONETIC_EDGES_MATRIX <- as.matrix(read.delim(file = "../Data/Cleaned/PHONETIC_EDGES_MATRIX.txt", sep = ","))

# Load distance df
WORD_LENGTH_EDGES_MATRIX <- as.matrix(read.delim(file = "../Data/Cleaned/WORD_LENGTH_EDGES_MATRIX.txt", sep = ","))
```

```{r}
# Save MATRICES for looping
PSYCHOLING_EDGE_MATRICES <- list(SEMANTIC_EDGES_MATRIX, PHONETIC_EDGES_MATRIX, WORD_LENGTH_EDGES_MATRIX)
PSYCHOLING_STRING <- list("SEMANTIC", "PHONETIC", "WORD_LENGTH")
```


# Run Functions
## Set variables
```{r}

ID_collumn_name <- "child_id"
Age_collumn_name <- "age"
Word_string_collumn_name = "item_definition"
Word_numeric_column_name = "item_id"
Is_word_known_collumn_name = "value"
```


```{r}
KNOWN_WORDS_NUMERIC <- unique(Child_Dataframe[[Word_numeric_column_name]]) 
KNOWN_WORDS_STRING <-  unique(colnames(SEMANTIC_EDGES_MATRIX)) 
KNOWN_WORDS_STRING[75] <- "breaks" # Changed from break to avoid making funcitons stop
```

```{r}
Running_all_functions <- function(
        List_of_subsets,
        Is_word_known_collumn_name,
        Word_string_collumn_name,
        KNOWN_WORDS_STRING,
        Linguistic_Matrix,
        Timepoint,
        PSY_NAME){
    #' First function
        Matrix <- Matrix
        
    #' Fifth function
        List_of_centrality_XD <- purrr::map()
        List_of_centrality <-  purrr::map(List_of_List_of_graphs, function(inner_list) {
            imap(inner_list, function(graph_object, index){
                eigen_centrality(graph_object, directed = FALSE)$vector[index] })}) # CHANGE HERE FOR DIFFERENT CENTRALITY MEASSUREMENT
        
        DF_Centrality <- rrapply::rrapply(List_of_centrality, how = "melt") %>%
            rename(Child_ID = L1, item_definition = L2) %>% 
            mutate(Timepoint = Timepoint,
                   value = format(value, scientific = FALSE,),
                   Linguistic_var = PSY_NAME)
        return(DF_Centrality)
}
```




## Execution Block
```{r}
for (i in 1:length(PSYCHOLING_EDGE_MATRICES)){
    PSY_NAME <- PSYCHOLING_STRING[[i]]
    PSY_MATRIX <- PSYCHOLING_EDGE_MATRICES[[i]]  # The adjacency edge matrix that is inputed in functions
    for (i_subset in 1:2){
        List_of_subsets <- (List_of_list_of_subsets[[i_subset]])
        DF_Centrality <- Running_all_functions(
            List_of_subsets = List_of_subsets,
            Is_word_known_collumn_name = Is_word_known_collumn_name,
            Word_string_collumn_name = Word_string_collumn_name,
            KNOWN_WORDS_STRING = KNOWN_WORDS_STRING,
            Linguistic_Matrix = PSY_MATRIX,
            Timepoint = i_subset,
            PSY_NAME = PSY_NAME)
        
        save_as_file_path <- paste0("../Data/Lexcial_information/",PSY_NAME,"_time_", i_subset,".csv")
        write.csv(x = DF_Centrality, file = save_as_file_path)
        }} 
```



```{r}

Semantics_Graph <- graph_from_adjacency_matrix(SEMANTIC_EDGES_MATRIX)
Semantic <- igraph:::eigen_centrality(graph = Semantics_Graph)
Phonetic_Graph <- graph_from_adjacency_matrix(PHONETIC_EDGES_MATRIX)
Phonetic <- igraph:::eigen_centrality(graph = Phonetic_Graph)
Word_length_Graph <- graph_from_adjacency_matrix(WORD_LENGTH_EDGES_MATRIX)
Word_length <- igraph:::eigen_centrality(graph = Word_length_Graph)

Global_centrality_df <- data_frame(item_definition = names(Semantic[[1]]), 
           Semantic = Semantic[[1]],
           Phonetic = Phonetic[[1]],
           Word_length = Word_length[[1]]
           )


write.csv(x = Global_centrality_df, file = "../Data/Global_centrality.csv")
```








